#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import subprocess as sp
import xmlrpc.client as rpc
import urllib.parse as up
import urllib.request as request
from bs4 import BeautifulSoup
from multiprocessing import Pool
import sys
import os
import os.path
import json
import time
import tempfile
import chardet

def parse_youtube_json(content, autonumber):
    dllist = []
    # discard the last empty line
    info = content.split("\n")[:-1]
    number = 0
    for line in info:
        episode = json.loads(line)
        if episode["playlist"]:
            playlist = episode["playlist"]
        else:
            playlist = ""
        formats = episode["formats"]
        index = 0
        # the last dash audio has best quality
        for fmt in formats:
            if fmt["format_note"] == "DASH audio":
                index += 1
            else:
                break
        number += 1
        if autonumber:
            prefix = str(number)+" - "
        else:
            prefix = ""
        basename = prefix + os.path.splitext(episode["_filename"])[0].replace('-'+episode["id"], '')
        name = basename+"-audio."+formats[index - 1]["ext"]
        # download the audio with best quality
        dllist.append({"dir":os.path.join(os.getcwd(), playlist.replace('/', '_').replace(':', '-')),
            "out":name, "url":formats[index - 1]["url"], "id":episode["id"]})
        videoWidth = 0
        videoSize = 0
        for index in range(index, len(formats)):
            if formats[index+1]["format_note"] != "DASH video" and int(formats[index]["width"]) == videoWidth and formats[index]["filesize"] > videoSize:
                break
            elif formats[index]["format_note"] != "DASH video":
                break
            videoWidth = int(formats[index]["width"])
            videoSize = formats[index]["filesize"]
        name = basename+"-video."+formats[index - 1]["ext"]
        # download the video with best quality but least size
        dllist.append({"dir":os.path.join(os.getcwd(), playlist.replace('/', '_').replace(':', '-')),
            "out":name, "url":formats[index - 1]["url"], "id":episode["id"]})
    return dllist

def get_download_list_youtube(url, autonumber):
    if os.path.exists("info.json"):
        print("use exists json file")
        with open("info.json", "r") as f:
            content = f.read()
    else:
        with sp.Popen(["youtube-dl", "-j", url], stdout=sp.PIPE) as proc:
            content = proc.stdout.read().decode("utf-8")
            with open("info.json", "w") as f:
                f.write(content)
    return parse_youtube_json(content, autonumber)

def download_youtube_subtitle(videoID, filename):
    keepVid = "http://keepvid.com/?url="+up.quote_plus("http://youtube.com/watch?v="+videoID)+"&mode=subs"
    with request.urlopen(keepVid) as html:
        soup = BeautifulSoup(html.read().decode("utf-8"), 'html.parser')
        dl = soup.find(id="dl")
        subs = dl.find_all("b", recursive=False)
        hrefs = dl.find_all("a", recursive=False)
        # first try to download the original subtitle, generated subtitle is the last choice
        for i in range(len(subs)):
            if subs[i].string == "English":
                find = i
                break
        if "find" not in locals():
            for i in range(len(subs)):
                if subs[i].string == "English (Automatic Captions)":
                    find = i
                    break
        if "find" in locals():
            with request.urlopen(hrefs[find]['href']) as html:
                with open(filename, "w") as f:
                    f.write(html.read().decode("utf-8"))
                    print("downloaded sub: "+filename)

def autonumber_downloaded(dllist):
    number = 0
    for i in range(len(dllist)):
        # each download has two parts, dash audio and dash video file
        if i % 2 == 0:
            number += 1
        filename = dllist[i]["out"]
        if os.path.exists(filename):
            os.rename(filename, str(number)+" - "+filename)

def get_download_list_ted(url):
    dllist = []
    # with open("info.json", "rb") as f:
    #     enc = chardet.detect(f.read(4096))["encoding"]
    # with open("info.json", "r", encoding=enc.replace("LE","").replace("BE","")) as f:
    #     info = f.read().split("\n")[:-1]
    with sp.Popen(["youtube-dl", "--sub-format", "srt", "--sub-lang", "en", "--write-sub", "-j", url], stdout=sp.PIPE) as proc:
        # discard the last empty line
        info = proc.stdout.read().decode("utf-8").split("\n")[:-1]
        for line in info:
            episode = json.loads(line)
            if episode["playlist"]:
                playlist = episode["playlist"]
            else:
                playlist = ""
            # put subtitle before video
            if episode["requested_subtitles"]:
                dllist.append({"dir":os.path.join(os.getcwd(), playlist.replace('/', '_').replace(':', '-')),
                    "out":os.path.splitext(episode["_filename"].replace('-'+episode["id"], ''))[0]+".srt", "url":episode["requested_subtitles"]["en"]["url"]})
            dllist.append({"dir":os.path.join(os.getcwd(), playlist.replace('/', '_').replace(':', '-')),
                "out":episode["_filename"].replace('-'+episode["id"], ''), "url":episode["url"]})
    return dllist

def get_download_list_others(url):
    dllist = []
    with sp.Popen(["youtube-dl", "-j", url], stdout=sp.PIPE) as proc:
        # discard the last empty line
        info = proc.stdout.read().decode("utf-8").split("\n")[:-1]
        for line in info:
            episode = json.loads(line)
            dllist.append({"dir":os.path.join(os.getcwd()),
                "out":episode["_filename"], "url":episode["url"]})
    # if the url is not supported, exit the application
    if "episode" not in locals():
        sys.exit("url not supported")
    # assume that even if there are several parts, they belong to one file 
    # after download finish, we will concatenate them.
    return dllist, episode["title"]+'.'+episode["ext"]

def aria2c_download(dllist):
    with rpc.ServerProxy('http://localhost:6800/rpc') as s:
        mc = rpc.MultiCall(s)
        for download in dllist:
            mc.aria2.addUri([download["url"]], {"dir":download["dir"], "out":download["out"]})
        gids = list(mc()) #real execute, don't forget to call this
        print("waiting for download finish......")

        errorCount = {}
        failedCount = 0
        while True:
            mc = rpc.MultiCall(s)
            for gid in gids:
                mc.aria2.tellStatus(gid, ["gid", "status", "completedLength"])
            completed = 0
            for stat in mc():
                if stat["status"] == "error":
                    index = gids.index(stat["gid"])
                    if index not in errorCount:
                        errorCount[index] = 1
                    else:
                        errorCount[index] += 1
                    if errorCount[index] > 5:
                        failedCount += 1
                        print("can not download: "+dllist[index]["out"])
                        print(dllist[index]["url"])
                        continue
                    gids.remove(stat["gid"])
                    print("download again: " + dllist[index]["out"])
                    s.aria2.removeDownloadResult(stat["gid"])
                    gid = s.aria2.addUri([dllist[index]["url"]], {"dir":dllist[index]["dir"], "out":dllist[index]["out"]})
                    gids.insert(index, gid)
                elif stat["status"] == "complete":
                    completed += 1
            if completed + failedCount == len(gids):
                break
            else:
                time.sleep(3)

def merge_youtube(dllist):
    i = 0
    while i < len(dllist):
        # each download has two parts, dash audio and dash video file
        audioFile = os.path.join(dllist[i]["dir"], dllist[i]["out"])
        videoFile = os.path.join(dllist[i+1]["dir"], dllist[i+1]["out"])
        if not os.path.exists(audioFile) or not os.path.exists(videoFile):
            i = i + 2
            continue
        final = os.path.splitext(videoFile.replace('-video', ''))[0]+".mkv"
        # try to download the subtitle
        srtFile = os.path.splitext(final)[0]+".srt"
        try:
            download_youtube_subtitle(dllist[i]["id"], srtFile)
        except:
            print("fail: http://keepvid.com/?url="+up.quote_plus("http://youtube.com/watch?v="+dllist[i]["id"])+"&mode=subs")
        i = i + 2
        # use mkv to merge the video and audio
        if os.path.exists(srtFile):
            sp.run(['ffmpeg', '-i', videoFile, '-i', audioFile, '-i', srtFile, '-map', '0:0', '-map', '1:0', '-map', '2:0', 
                '-vcodec', 'copy', '-acodec', 'copy', '-scodec', 'copy', final], stdout=sp.PIPE, stderr=sp.PIPE)
        else:
            sp.run(['ffmpeg', '-i', videoFile, '-i', audioFile, '-map', '0:0', '-map', '1:0', '-vcodec', 'copy', '-acodec', 'copy', final],
                    stdout=sp.PIPE, stderr=sp.PIPE)
        # remove the orignal files
        os.remove(videoFile)
        os.remove(audioFile)
        if os.path.exists(srtFile):
            os.remove(srtFile)
        print("final file:" + final)

def merge_ted(dllist):
    i = 0
    while i < len(dllist):
        srtFile = ""
        if os.path.splitext(dllist[i]["out"])[1] == ".srt":
            srtFile = os.path.join(dllist[i]["dir"], dllist[i]["out"])
            videoFile = os.path.join(dllist[i+1]["dir"], dllist[i+1]["out"])
            i = i + 2
        else:
            videoFile = os.path.join(dllist[i]["dir"], dllist[i]["out"])
            i = i + 1

        if not os.path.exists(videoFile):
            continue
        if srtFile != "":
            # use mkv to merge the video and srt
            final = os.path.splitext(videoFile)[0]+".mkv"
            sp.run(['ffmpeg', '-i', videoFile, '-i', srtFile, '-map', '0:0', '-map', '0:1', '-map', '1:0', 
                '-vcodec', 'copy', '-acodec', 'copy', '-scodec', 'copy', final], stdout=sp.PIPE, stderr=sp.PIPE)
            os.remove(videoFile)
            os.remove(srtFile)
            print("final file:" + final)

def merge_others(dllist, final):
    if len(dllist) > 1:
        tmp = tempfile.mkstemp(suffix=".txt", dir=os.getcwd(), text=True)[1]
        with open(tmp, "w") as f:
            for download in dllist:
                f.write("file '"+download["out"]+"'\n")
        # refer to https://trac.ffmpeg.org/wiki/Concatenate
        sp.run(['ffmpeg', '-f', 'concat', '-i', tmp, '-c', 'copy', final], stdout=sp.PIPE, stderr=sp.PIPE)
        os.remove(tmp)
        for download in dllist:
            os.remove(download["out"])
    else:
        if os.path.exists(dllist[0]["out"]):
            os.rename(dllist[0]["out"], final)
    # movist doesn't support f4v, convert to mp4, just change the file format, it's fast
    if sys.platform == "darwin" and os.path.splitext(final)[1] == ".f4v" and os.path.exists(final):
        sp.run(['ffmpeg', '-i', final, '-vcodec', 'copy', '-acodec', 'copy', os.path.splitext(final)[0]+".mp4"], stdout=sp.PIPE, stderr=sp.PIPE)
        os.remove(final)
    print("final file:" + final)

def download_video(url, autonumber=False):
    if "youtube" in url:
        dllist = get_download_list_youtube(url, autonumber)
        # for remedy
        # autonumber_downloaded(dllist)
    elif "ted.com" in url:
        dllist = get_download_list_ted(url)
    else:
        dllist, others_final = get_download_list_others(url)

    aria2c_download(dllist)

    if "youtube" in url:
        merge_youtube(dllist)
    elif "ted.com" in url:
        merge_ted(dllist)
    else:
        merge_others(dllist, others_final)

def bundle_download(listFile):
    with open(listFile, "r") as f:
        urls = f.readlines()
        with Pool(5) as p:
            p.map(download_video, urls)

if __name__ == "__main__":
    if len(sys.argv) < 2:
        sys.exit("Error: there's no download url")
    elif len(sys.argv) == 3 and sys.argv[1] == "-an":
        download_video(sys.argv[2], autonumber=True)
    elif len(sys.argv) == 3 and sys.argv[1] == "-f":
        bundle_download(sys.argv[2])
    else:
        download_video(sys.argv[1])
